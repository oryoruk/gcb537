#!usr/bin/python

# NAME:  ONUR YORUK
# CLASS: GCB537 - SPRING 2016
# EXERCISE 2 PROGRAMMING

import pickle
import numpy as np
from scipy import linalg
import matplotlib.pyplot as plt
import matplotlib
import pandas as pd
pd.options.display.mpl_style = 'default'

INPUT_DIR = '../Ex2Prog/'
OUTPUT_DIR = '../output/'


# function for residual sum of squares
def rss(y, y_hat):
    return np.power(y - y_hat, 2).sum()

#function that returns indices for cross validation
def CV_fold_indices(total_no, CV_fold_no):
    fold_size = total_no/int(CV_fold_no)
    indices = []
    starts = range(0,total_no,fold_size)[:CV_fold_no]
    ends = range(0, total_no,fold_size)[1:CV_fold_no] + [total_no]
    return zip(starts, ends)

# provided ridge regression function
def ridge(A, b, alphas):
    """
    Return coefficients for regularized least squares

         min ||A x - b||^2 + alpha ||x||^2

    Parameters
    ----------
    A : array, shape (n, p)
    b : array, shape (n,)
    alphas : array, shape (k,)

    Returns
    ----------
    coef: array, shape (p, k)
    """

    U, s, Vt = linalg.svd(A, full_matrices=False)
    d = s / (s[:, np.newaxis].T ** 2 + alphas[:, np.newaxis])
    return np.dot(d * U.T.dot(b), Vt).T

def save_output(file_name, best_lambda, rss, bias_term, coeffs):
    fo = open(OUTPUT_DIR+ file_name+'_results' + ".output", "w")
    output = '#InputFile: ' + file_name + '\n'
    output += "#Lambda " + str(best_lambda)  + '\n'
    output += "#RSS " + str(rss) + '\n'
    output += "#W0 " + str(bias_term) + '\n'
    for i, coef in enumerate(coeffs):
        output += "#W" + str(i+1) + " " + str(coef) + '\n'
    fo.write(output)
    fo.close()
    return None

# loading serialized files generated by 'generateX.py'
X_filename = OUTPUT_DIR + 'probs_of_being_regulated.pickle'
y_array_filename = OUTPUT_DIR + 'experiments.pickle'

fileObject = open(X_filename, 'r')
X = pickle.load(fileObject)
fileObject = open(y_array_filename, 'r')
y_array = pickle.load(fileObject)

print 'variables from previous script loaded'


n, p = X.shape
_, exp_no = y_array.shape
#code to train with cross validation
#set lambdas
k = 500
lambdas = np.logspace(-10,3,k)
cv_fold_no = 10

#for each experiment
for i in range(exp_no):
    exp_dataset = 'Expression'+str(i+1)
    print '\nstarting the analysis for dataset: ' + exp_dataset

    #get the y vector that corresponds to the experiment
    y = y_array[:,i]
    test_rss_per_lambda = np.zeros(k,)
    y_hat_per_lambda = np.zeros((n,k))
    #for each fold
    #code to train with cross validation:
    for fold_start,fold_end in CV_fold_indices(n, cv_fold_no):
        fold_train_X = np.concatenate( [X[:fold_start,:],X[fold_end:,:]])
        fold_test_X = X[fold_start:fold_end,:]
        fold_train_y = np.concatenate([y[:fold_start],y[fold_end:]])
        fold_test_y = y[fold_start:fold_end]
        #run ridge regression on the cv training set (fold left out)
        coefs_array = ridge(fold_train_X,fold_train_y,lambdas)
        #for each lambda
        for j in range(k):
            bias_term = (fold_train_y - np.dot(fold_train_X, coefs_array[:,j])).mean()
            fold_test_y_hat = np.dot(fold_test_X, coefs_array[:,j])+bias_term
            #print bias_term, rss(fold_test_y, fold_test_y_hat)
            test_rss_per_lambda[j] += rss(fold_test_y, fold_test_y_hat)
            y_hat_per_lambda[fold_start:fold_end,j] = fold_test_y_hat
    #pick best lambda based on rss
    best_lambda_index = np.argmin(test_rss_per_lambda)
    best_lambda = lambdas[best_lambda_index]
    print 'cross validation complete for dataset: ' + exp_dataset
    print 'ridge hyper parameter yielding best rss is: ' + str(best_lambda)
    best_rss, best_biasterm, best_coeffs = 0.0,0.0, []
    #associated rss
    #min(rss_per_lambda)
    #now train using whole data:
    train_rss_per_lambda = np.zeros(k,)
    #run ridge regression on the cv training set (fold left out)
    #running ridge for the entire dataset
    coefs_array = ridge(X,y,lambdas)
    #for each lambda
    for j in range(k):
        bias_term = (y - np.dot(X, coefs_array[:,j])).mean()
        y_hat = np.dot(X, coefs_array[:,j])+bias_term
        #print bias_term, rss(fold_test_y, fold_test_y_hat)
        train_rss_per_lambda[j] += rss(y, y_hat)
        if j == best_lambda_index:
            best_biasterm = bias_term
            best_rss = rss(y, y_hat)
            best_coeffs = coefs_array[:,j]
    #save output file:
    print 'final training with whole dataset complete for dataset: ' + exp_dataset
    save_output(exp_dataset, best_lambda, best_rss, best_biasterm, best_coeffs)
    print 'output saved'
    #here comes visualization:
    # here comes visualization:
    ##########
    # TODO: code to visualize the relationship between lambda and accuracy (RSS) in test and whole (train) data
    font = {'family': 'normal',
            'weight': 'normal',
            'size': 25}
    matplotlib.rc('font', **font)

    plt.figure(figsize=(30, 10))
    ax = plt.gca()
    ax.set_xscale('log')
    ax.plot(lambdas, test_rss_per_lambda, label='testing_data')
    ax.plot(lambdas, train_rss_per_lambda, label='training_data')
    ymin, ymax = ax.get_ylim()
    ax.vlines(best_lambda, ymin=ymin, ymax=ymax, alpha=1, color='r', label='best_lambda: ' + str(best_lambda))
    ax.set_title('Accuracy vs. Regularization/Shrinkage (' + exp_dataset + ')')
    plt.xlabel('lambdas')
    plt.ylabel('inverse accuracy (rss)')
    plt.legend()
    #plt.show()
    plt.savefig(OUTPUT_DIR +  exp_dataset + '_plot1_acc_reg.png', bbox_inches='tight', dpi=300)

    # TODO: visualize all data complexity / lambda (shrinkage of coefficients)
    plt.figure(figsize=(30, 10))
    ax = plt.gca()
    # ax.set_color_cycle(['b', 'r', 'g', 'c', 'k', 'y', 'm'])
    ax.set_xscale('log')
    ax.set_xlim([10 ** -10, 10 ** 3])  # reverse axis
    # ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis
    ax.set_ylim([-1000, 1000])
    ymin, ymax = ax.get_ylim()
    ax.vlines(best_lambda, ymin=ymin, ymax=ymax, alpha=1, color='r', label='best_lambda: ' + str(best_lambda))
    ax.plot(lambdas, coefs_array.T)
    ax.set_title('Complexity vs. Regularization/Shrinkage (Zoomed In ,' + exp_dataset + ')')
    plt.xlabel('lambdas')
    plt.ylabel('coefficients')
    plt.legend()
    #plt.show()
    plt.savefig(OUTPUT_DIR +  exp_dataset + '_plot2_comp_reg_I.png', bbox_inches='tight', dpi=300)

    plt.figure(figsize=(30, 10))
    ax = plt.gca()
    # ax.set_color_cycle(['b', 'r', 'g', 'c', 'k', 'y', 'm'])
    ax.set_xscale('log')
    ax.set_xlim([10 ** -10, 10 ** 3])  # reverse axis
    # ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis
    ax.set_ylim([-10000, 10000])
    ymin, ymax = ax.get_ylim()
    ax.vlines(best_lambda, ymin=ymin, ymax=ymax, alpha=1, color='r', label='best_lambda: ' + str(best_lambda))
    ax.plot(lambdas, coefs_array.T)
    ax.set_title('Complexity vs. Regularization/Shrinkage (Zoomed Out ,' + exp_dataset + ')')
    plt.xlabel('lambdas')
    plt.ylabel('coefficients')
    plt.legend()
    #plt.show()
    plt.savefig(OUTPUT_DIR +  exp_dataset + '_plot3_comp_reg_II.png', bbox_inches='tight', dpi=300)
    print 'visualizations saved'
    ##########


print '\nanalysis complete'

